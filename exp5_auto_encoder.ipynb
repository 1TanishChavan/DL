{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Load MNIST dataset\n",
    "(X_train, _), (X_test, _) = mnist.load_data()\n",
    "\n",
    "\n",
    "# Normalize pixel values to between 0 and 1\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "\n",
    "\n",
    "# Flatten the images into vectors (784-dimensional)\n",
    "X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
    "\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]  # 784 for MNIST\n",
    "encoding_dim = 32  # Compression factor of 24.5 (784 / 32)\n",
    "\n",
    "\n",
    "# Encoder\n",
    "input_img = Input(shape=(input_dim,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# Decoder\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "# Autoencoder model\n",
    "autoencoder = Model(input_img, decoded)\n",
    "# Compile the model\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the autoencoder\n",
    "history = autoencoder.fit(X_train, X_train,\n",
    "                          epochs=50,\n",
    "                          batch_size=256,\n",
    "                          shuffle=True,\n",
    "                          validation_data=(X_test, X_test))\n",
    "\n",
    "\n",
    "\n",
    "# Plot training loss and validation loss over epochs\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Encode and decode some digits\n",
    "decoded_imgs = autoencoder.predict(X_test)\n",
    "\n",
    "\n",
    "# Plot some examples\n",
    "n = 10  # Number of digits to display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Original images\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "# Reconstructed images\n",
    "ax = plt.subplot(2, n, i + 1 + n)\n",
    "plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "plt.suptitle('Original (Top) vs Reconstructed (Bottom) Images')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Model for Image Compression/Denoising\n",
    "\n",
    "**Autoencoders** are a type of neural network designed for unsupervised learning tasks like image compression and denoising. They consist of two main components: an **encoder** and a **decoder**.\n",
    "\n",
    "#### 1. **Architecture of Autoencoder**\n",
    "- **Encoder**: The encoder compresses the input image into a smaller representation (latent space). It reduces the dimensionality of the input by mapping the image to a lower-dimensional space, capturing the essential features.\n",
    "  \n",
    "- **Latent Space**: This is a compressed representation of the input image. For image compression, it contains the most important information from the original image, ignoring irrelevant details.\n",
    "\n",
    "- **Decoder**: The decoder reconstructs the image from the compressed latent space representation. It aims to reproduce an image as close as possible to the original input image.\n",
    "\n",
    "#### 2. **Working of Autoencoder for Image Compression/Denoising**\n",
    "- **Image Compression**: The goal here is to reduce the image size by encoding it into fewer dimensions and then decode it back. This is helpful when we need to store or transmit large image datasets.\n",
    "  \n",
    "- **Image Denoising**: For denoising, the autoencoder is trained to remove noise from images. The input images are noised, and the output is the clean, original image. The encoder learns the key features of the image, ignoring the noise, while the decoder reconstructs the noise-free image.\n",
    "\n",
    "#### 3. **Loss Function and Optimization**\n",
    "Autoencoders use a loss function (e.g., **mean squared error** or **binary cross-entropy**) to measure the difference between the original and reconstructed images. Optimization algorithms like **Adam** adjust the weights in the network to minimize this reconstruction error.\n",
    "\n",
    "#### 4. **Key Points in Designing an Autoencoder**\n",
    "- **Input Layer**: Matches the dimensionality of the image (e.g., 28x28 pixels for MNIST, flattened to 784 neurons).\n",
    "- **Hidden Layers**: Gradually reduce dimensions in the encoder and symmetrically increase dimensions in the decoder.\n",
    "- **Latent Space**: Defines the compressed representation (e.g., 32-dimensional).\n",
    "- **Output Layer**: Should match the input dimension (e.g., 784 neurons for a flattened MNIST image).\n",
    "\n",
    "#### Diagram of Autoencoder Architecture:\n",
    "```\n",
    "Input Image (e.g., 28x28) \n",
    "         │\n",
    "         ▼\n",
    "    Encoder Network\n",
    "         │\n",
    "    (Compressed Representation - Latent Space)\n",
    "         │\n",
    "         ▼\n",
    "    Decoder Network\n",
    "         │\n",
    "         ▼\n",
    "Reconstructed Image\n",
    "```\n",
    "\n",
    "### Applications:\n",
    "1. **Image Compression**: Efficiently reduces image size while preserving essential details.\n",
    "2. **Image Denoising**: Removes noise and restores clean images, useful in photography and medical imaging.\n",
    "\n",
    "By training an autoencoder model, we can perform both image compression and denoising, improving storage efficiency and image quality.\n",
    "\n",
    "Good luck with your practical exam!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/6715be02-b2c0-800d-b2bb-1251f833fdc6"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

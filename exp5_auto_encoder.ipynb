{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Load MNIST dataset\n",
    "(X_train, _), (X_test, _) = mnist.load_data()\n",
    "\n",
    "\n",
    "# Normalize pixel values to between 0 and 1\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "\n",
    "\n",
    "# Flatten the images into vectors (784-dimensional)\n",
    "X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
    "\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]  # 784 for MNIST\n",
    "encoding_dim = 32  # Compression factor of 24.5 (784 / 32)\n",
    "\n",
    "\n",
    "# Encoder\n",
    "input_img = Input(shape=(input_dim,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# Decoder\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "# Autoencoder model\n",
    "autoencoder = Model(input_img, decoded)\n",
    "# Compile the model\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the autoencoder\n",
    "history = autoencoder.fit(X_train, X_train,\n",
    "                          epochs=50,\n",
    "                          batch_size=256,\n",
    "                          shuffle=True,\n",
    "                          validation_data=(X_test, X_test))\n",
    "\n",
    "\n",
    "\n",
    "# Plot training loss and validation loss over epochs\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Encode and decode some digits\n",
    "decoded_imgs = autoencoder.predict(X_test)\n",
    "\n",
    "\n",
    "# Plot some examples\n",
    "n = 10  # Number of digits to display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Original images\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "# Reconstructed images\n",
    "ax = plt.subplot(2, n, i + 1 + n)\n",
    "plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "plt.suptitle('Original (Top) vs Reconstructed (Bottom) Images')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
